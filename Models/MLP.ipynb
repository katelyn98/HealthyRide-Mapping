{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "presidential-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "convinced-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 layer MLP with one hidden layer\n",
    "class MultilayerPerceptron(nn.Module):\n",
    "    #define network\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) # input layer -> hidden layer\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    #define forward function\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "provincial-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, dataloader, func_loss, opt, num_epochs, experiment_name):\n",
    "    model.train()\n",
    "    best_model = None\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for i, batched_data in enumerate(dataloader): \n",
    "            inputs, targets = batched_data\n",
    "#             print(\"inputs: \" + str(inputs.shape))\n",
    "#             print(\"target: \" + str(targets.shape))\n",
    "            \n",
    "            output_prob = model(inputs) #pass images through model to get probability for each class (1 x 10 dim)\n",
    "            loss = func_loss(output_prob.squeeze(), targets)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            loss.backward() #performing back prop\n",
    "            opt.step() #updating the weights\n",
    "            opt.zero_grad() #reset gradients\n",
    "            \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(output_prob == targets.data)\n",
    "        \n",
    "        epoch_loss = running_loss / 100\n",
    "        epoch_acc = running_corrects.double() / 100\n",
    "        \n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_model, os.path.join(experiment_name,\n",
    "                                                'best_model.pt'))\n",
    "            \n",
    "        if epoch % 5 == 0:\n",
    "            if epoch_acc > 50:\n",
    "                print(\"accuracy for epoch: \" + str(epoch_acc))\n",
    "            print('Epoch: ' + str(epoch) + ' Final loss is: ' + str(loss.item()))\n",
    "            \n",
    "    print('Epoch: ' + str(epoch) + ' Final loss is: ' + str(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "established-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('../Data/PGH/DemandPrediction/ml_df.csv')\n",
    "# df = df.drop(columns=['Unnamed: 0', 'median_hh_income','mean_hh_income','in_labor_force', 'civ_labor_force', \n",
    "#                       'employed','unemployed', 'perc_employed', 'perc_unemployed','own_alone', \n",
    "#                       'carpool', 'public_transit', 'walked', 'other', 'wfh','mean_travel_time_to_work', \n",
    "#                       'perc_public', 'perc_alone', 'perc_walk','perc_other', '2018_outflow', '2019_outflow', '2020_outflow'])\n",
    "df = pd.read_csv('../Data/PGH/outflow_pgh_monthly.csv')\n",
    "df = df.drop(columns=['station_id', 'tractce10'])\n",
    "\n",
    "for row in range(len(df)):\n",
    "    for col in df.columns:\n",
    "        if df.loc[row][col] == '-' or pd.isna(df.loc[row][col]):\n",
    "            df.at[row,col] = 0\n",
    "            \n",
    "df = df.fillna(0)\n",
    "            \n",
    "\n",
    "X = torch.from_numpy(df.iloc[:, 0:67].to_numpy()).type(torch.float)\n",
    "y = torch.from_numpy(df.iloc[:, 67].to_numpy()).type(torch.float)\n",
    "\n",
    "# mean = torch.mean(X, axis=0)\n",
    "# stdev = torch.std(X, axis=0)\n",
    "# X = (X - mean)/stdev\n",
    "print(len(X))\n",
    "\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "train_ds, test_ds = random_split(dataset, [70, 30])\n",
    "batch_size=1\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "hourly-assembly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_size = len(df.iloc[:,0:67].columns)\n",
    "output_size = 1\n",
    "input_size,output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "utility-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, dataloader, func_loss):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        right, running_total = 0, 0\n",
    "\n",
    "        for i, batched_data in enumerate(dataloader):\n",
    "\n",
    "            #moving tensors to the GPU\n",
    "            inputs, targets = batched_data #grab the batch of images as tensors and grab the batch of labels as tensors\n",
    "\n",
    "            output_probs = model(inputs) #pass images through model to get probability for each class (1 x 10 dim)\n",
    "\n",
    "            loss = func_loss(output_probs.squeeze(), targets)\n",
    "            print(\"loss: \" + str(loss))\n",
    "            total_loss += loss\n",
    " \n",
    "        print('Total Loss L1: ' + str(total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-investment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "tamil-acting",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Final loss is: 13.293106079101562\n",
      "Epoch: 5 Final loss is: 3.078004837036133\n",
      "Epoch: 10 Final loss is: 8.035240173339844\n",
      "Epoch: 15 Final loss is: 4.980989456176758\n",
      "Epoch: 20 Final loss is: 10.992538452148438\n",
      "Epoch: 25 Final loss is: 4.951473236083984\n",
      "Epoch: 30 Final loss is: 6.953508377075195\n",
      "Epoch: 35 Final loss is: 7.886628150939941\n",
      "Epoch: 40 Final loss is: 31.9925537109375\n",
      "Epoch: 45 Final loss is: 5.9711103439331055\n",
      "Epoch: 50 Final loss is: 7.93890380859375\n",
      "Epoch: 55 Final loss is: 5.177516937255859\n",
      "Epoch: 60 Final loss is: 5.021839141845703\n",
      "Epoch: 65 Final loss is: 2.0767364501953125\n",
      "Epoch: 70 Final loss is: 0.010975837707519531\n",
      "Epoch: 75 Final loss is: 3.9782304763793945\n",
      "Epoch: 80 Final loss is: 0.9392175674438477\n",
      "Epoch: 85 Final loss is: 43.27016067504883\n",
      "Epoch: 90 Final loss is: 10.909214973449707\n",
      "Epoch: 95 Final loss is: 4.886701583862305\n",
      "Epoch: 100 Final loss is: 11.926839828491211\n",
      "Epoch: 105 Final loss is: 9.909698486328125\n",
      "Epoch: 110 Final loss is: 3.493607521057129\n",
      "Epoch: 115 Final loss is: 10.107786178588867\n",
      "Epoch: 120 Final loss is: 10.825090408325195\n",
      "Epoch: 125 Final loss is: 6.8493499755859375\n",
      "Epoch: 130 Final loss is: 13.99533462524414\n",
      "Epoch: 135 Final loss is: 3.895878791809082\n",
      "Epoch: 140 Final loss is: 0.27045631408691406\n",
      "Epoch: 145 Final loss is: 1.957901954650879\n",
      "Epoch: 150 Final loss is: 2.0994043350219727\n",
      "Epoch: 155 Final loss is: 10.085996627807617\n",
      "Epoch: 160 Final loss is: 1.7971200942993164\n",
      "Epoch: 165 Final loss is: 48.97294235229492\n",
      "Epoch: 170 Final loss is: 1.8414630889892578\n",
      "Epoch: 175 Final loss is: 2.1164464950561523\n",
      "Epoch: 180 Final loss is: 7.95054817199707\n",
      "Epoch: 185 Final loss is: 10.9495267868042\n",
      "Epoch: 190 Final loss is: 0.09458160400390625\n",
      "Epoch: 195 Final loss is: 11.0560884475708\n",
      "Epoch: 200 Final loss is: 2.088512420654297\n",
      "Epoch: 205 Final loss is: 8.95956802368164\n",
      "Epoch: 210 Final loss is: 11.06088924407959\n",
      "Epoch: 215 Final loss is: 9.90064525604248\n",
      "Epoch: 220 Final loss is: 4.058393478393555\n",
      "Epoch: 225 Final loss is: 6.823163986206055\n",
      "Epoch: 230 Final loss is: 11.815268516540527\n",
      "Epoch: 235 Final loss is: 7.0690813064575195\n",
      "Epoch: 240 Final loss is: 22.10162353515625\n",
      "Epoch: 245 Final loss is: 9.948225021362305\n",
      "Epoch: 250 Final loss is: 5.182249069213867\n",
      "Epoch: 255 Final loss is: 10.971590042114258\n",
      "Epoch: 260 Final loss is: 43.09202575683594\n",
      "Epoch: 265 Final loss is: 6.775692939758301\n",
      "Epoch: 270 Final loss is: 0.8811025619506836\n",
      "Epoch: 275 Final loss is: 10.909889221191406\n",
      "Epoch: 280 Final loss is: 10.014636993408203\n",
      "Epoch: 285 Final loss is: 0.08333683013916016\n",
      "Epoch: 290 Final loss is: 0.23893260955810547\n",
      "Epoch: 295 Final loss is: 7.9217424392700195\n",
      "Epoch: 300 Final loss is: 2.0273962020874023\n",
      "Epoch: 305 Final loss is: 2.9050941467285156\n",
      "Epoch: 310 Final loss is: 9.00968074798584\n",
      "Epoch: 315 Final loss is: 7.875790596008301\n",
      "Epoch: 320 Final loss is: 5.838515281677246\n",
      "Epoch: 325 Final loss is: 31.95989990234375\n",
      "Epoch: 330 Final loss is: 22.106590270996094\n",
      "Epoch: 335 Final loss is: 2.773204803466797\n",
      "Epoch: 340 Final loss is: 7.917259216308594\n",
      "Epoch: 345 Final loss is: 5.937800407409668\n",
      "Epoch: 350 Final loss is: 48.93418884277344\n",
      "Epoch: 355 Final loss is: 1.1885509490966797\n",
      "Epoch: 360 Final loss is: 6.024921417236328\n",
      "Epoch: 365 Final loss is: 11.170429229736328\n",
      "Epoch: 370 Final loss is: 12.947098731994629\n",
      "Epoch: 375 Final loss is: 1.0687808990478516\n",
      "Epoch: 380 Final loss is: 8.010210037231445\n",
      "Epoch: 385 Final loss is: 4.027443885803223\n",
      "Epoch: 390 Final loss is: 8.963586807250977\n",
      "Epoch: 395 Final loss is: 3.9753379821777344\n",
      "Epoch: 400 Final loss is: 4.036540985107422\n",
      "Epoch: 405 Final loss is: 1.0201807022094727\n",
      "Epoch: 410 Final loss is: 8.98459529876709\n",
      "Epoch: 415 Final loss is: 4.046034812927246\n",
      "Epoch: 420 Final loss is: 5.058198928833008\n",
      "Epoch: 425 Final loss is: 12.037362098693848\n",
      "Epoch: 430 Final loss is: 49.164913177490234\n",
      "Epoch: 435 Final loss is: 11.126688957214355\n",
      "Epoch: 440 Final loss is: 5.144510269165039\n",
      "Epoch: 445 Final loss is: 17.02960777282715\n",
      "Epoch: 450 Final loss is: 9.033492088317871\n",
      "Epoch: 455 Final loss is: 32.00386047363281\n",
      "Epoch: 460 Final loss is: 6.867090225219727\n",
      "Epoch: 465 Final loss is: 8.965200424194336\n",
      "Epoch: 470 Final loss is: 49.20109176635742\n",
      "Epoch: 475 Final loss is: 9.797109603881836\n",
      "Epoch: 480 Final loss is: 22.095409393310547\n",
      "Epoch: 485 Final loss is: 0.012148857116699219\n",
      "Epoch: 490 Final loss is: 0.18921566009521484\n",
      "Epoch: 495 Final loss is: 9.791165351867676\n",
      "Epoch: 499 Final loss is: 8.862854957580566\n"
     ]
    }
   ],
   "source": [
    "# model = MultilayerPerceptron(input_size, 150, output_size)\n",
    "model = nn.Sequential(nn.Linear(input_size, 5), nn.ELU(),\n",
    "                     nn.Linear(5, 9), nn.ELU(),\n",
    "                     nn.Linear(9, 9), nn.ELU(),\n",
    "                     nn.Linear(9, 5), nn.ELU(),\n",
    "                     nn.Linear(5, 1))\n",
    "epochs = 500\n",
    "learning_rate = 1e-4\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4, momentum=0.99)\n",
    "training(model, train_loader, nn.L1Loss(), optimizer, epochs, \"test1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "simplified-richardson",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(9.0703)\n",
      "loss: tensor(2.9297)\n",
      "loss: tensor(0.0703)\n",
      "loss: tensor(9.9297)\n",
      "loss: tensor(4.9297)\n",
      "loss: tensor(2.0703)\n",
      "loss: tensor(6.9297)\n",
      "loss: tensor(4.0703)\n",
      "loss: tensor(10.9297)\n",
      "loss: tensor(13.9297)\n",
      "loss: tensor(6.9297)\n",
      "loss: tensor(0.9297)\n",
      "loss: tensor(15.0703)\n",
      "loss: tensor(11.9297)\n",
      "loss: tensor(26.0703)\n",
      "loss: tensor(10.9297)\n",
      "loss: tensor(2.9297)\n",
      "loss: tensor(42.0703)\n",
      "loss: tensor(13.9297)\n",
      "loss: tensor(26.0703)\n",
      "loss: tensor(6.9297)\n",
      "loss: tensor(127.0703)\n",
      "loss: tensor(3.9297)\n",
      "loss: tensor(9.9297)\n",
      "loss: tensor(9.9297)\n",
      "loss: tensor(3.0703)\n",
      "loss: tensor(9.9297)\n",
      "loss: tensor(12.9297)\n",
      "loss: tensor(5.9297)\n",
      "loss: tensor(2.0703)\n",
      "Total Loss L1: tensor(413.4374)\n"
     ]
    }
   ],
   "source": [
    "evaluation(model, test_loader, nn.L1Loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-reward",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
